\subsection{Toolkit introduction}
4 components, what should it do (online/offline), image2image, gal2gal, cat2cat, albert drawing

\subsection{Data collection}
\subsection{Feature extraction}
\subsection{Classification}
\subsection{Visualization}

% toolboxes used
\subsection{Data collection}
[Sander, Bart B.]
% xml format
% network

DeviantArt provides users, also called deviants, galleries of their images. 
When someone visits such a gallery a featured page will be shown. Furthermore
the user is provided with options to browse the gallery or visit a sub gallery
defined by the user. There are various types of members: normal members, premium 
members, banned members, staff members, etc. Premium members have extra benefits
like no ads, gallery customization, beta-test new site features and more.

DeviantArt does not provide a web api to download images. This makes it more 
difficult to download images. On top of that changes to the website can possible break
down the downloading application.

DeviantArt does provide rss, which allows us to download xml files containing 
information about the users galleries. RSS xml files are more easy to parse
than the html gallery pages.

For each image the full sized image and two different sized thumbnails are 
available. DeviantArt supports png, jpeg, bmp and gif image formats.

% gallery/images
% Initial approach
% 1. Retrieve backend url from http://deviant.deviantart.com/gallery (using the SMGL Parser included with python)
% 2. Retrieve the xml file from the backend (Using python xml.sax parser)
% 3. Parse all items from the xml file. Follow the links to the full images and thumbsnail. Download them.
% 4. Increase the offset parameter and parse the next xml file to retrieve all images from the deviant. Keep doing this until no items are left
% 5. The following file structure is created (add example):
%      - For each deviant a seperate folder is created. In this folder another three folders are created for the full sized images and the big and small thumbnails.
%      - For each image of the deviant a xml file is written containing the filename, deviantart link and title.
% Problems
% - The backend link in gallery page doesn't seems to have all images (only the ones in the features pages).
% - Downloading of images might fail due problems on the server side
% Approach refined
% - Instead of retrieving the backend url from the gallery page follow this link directly:
%    http://backend.deviantart.com/rss.xml?q=gallery:$deviant$&offset=0
%   Don't safe the xml file for the failed images. Remove corrupted images. Try to download again at a later point.
In order to create our dataset we needed to download the images from Deviantart. 
The \textit{Gallery Scraper} is written in Python and retrieves all images for a given 
list of deviants. In our initial approach we retrieved 
the backend link from \textit{http://deviant.deviantart.com/gallery} using the 
SGML(Standard Generalized Mark-up Language) parser included in the sgmllib Python module. The backend link points 
to a xml file containing the first 60 images of the deviant. TO retrieve the other 
xml files we needed to change the offset in the url. 

We parsed the xml files using the xml.sax module included with Python. 
For each item in the xml file a link to the full sized image, a big thumbnail and 
a small thumbnail are provided. The big thumbnails are usually around 300 width and 
the small thumbnails around 150 height. For each deviant we created a seperate folder, which
contains three subfolders for the different sized images. 

For each image of the deviant a xml file is written containing the filename, category, deviantart link and title.
An example of such a xml file looks like this:

(Insert example here)

Although this initial approach seems to work we did encountered a few problems. First it
seems the backend link on the gallery page only contains the images listed under \textit{featured}, 
which does not necessarily contains all images of the deviant. After some more investigation it turns 
out we can retrieve the xml file containing all images directly from the url 
\textit{$http://backend.deviantart.com/rss.xml?q=gallery:\$deviant\$$}.

The second problem is that downloading an image might fail due problems at the server side of DeviantArt.
We solved this by removing corrupt downloads and not generating a xml file for the image. Then at a later
point we run the scraper and try to download the missing images again. 

% quick analysis tool
%\subsubsection{Quick Analysis Tool}
% Prints category statistics per user or over the whole dataset
% Option to print sub categories
% Example print
To retrieve statistics about the dataset we made a quick analysis tool. It reads in
all image xml files using the xml.minidom Python module  and counts the categories. 
It has an option to this per user or for the whole dataset. It also has an option
to only print the top category statistics or also print per sub category.

An analysis including the sub categories looks like this:

(Insert example here)

\subsection{Feature extraction}
When working with images, it is usually not possible to work with the raw image data (the pixel values). The reason for this is the high dimensionality of images, which can easily exist in a space of more than a million dimensions. By extracting features from images, they can be represented in a lower dimensional feature-space.  This feature extraction process has several advantages:
\begin{itemize}
\item The data becomes computationally easier to work with due to the smaller number of dimensions
\item By using the right features, the data becomes more suitable for generalization across images
\item Reducing the dimensionality makes it easier to visualize sets of images
\item Features can have an intuitive basis, which makes it easier for non-computer-scientists to analyze (sets of) images
\end{itemize}
\textit{Here something general about different kinds of image features}

% Computer vision is an important and maturing engineering science. It underpins an increasing variety of applications that require the acquisition, analysis, and interpretation of visual information.
In the extraction of image features, a distinction was made between low-level statistical features and higher level cognitive-based features....

\subsubsection{Statistical features}
As statistical features, many relatively simple low-level features were extracted from the images. Below is a list of all features and their meaning:
\begin{itemize}
\item Edge ratio: description
\item Corner ratio: description
\item etc...
\end{itemize}

\subsubsection{Cognitively-inspired features}
One of the more recent trends in computer vision research in the pursuit of human-like capability is the coupling of cognition and vision into cognitive computer vision. 
The term cognitive computer vision has been introduced with the aim of achieving more robust, resilient, and adaptable computer vision systems by endowing them with a cognitive faculty: the ability to learn, adapt, weigh alternative solutions, and develop new strategies for analysis and interpretation.

In our project we focus on computational models of focal visual attention. Attention allows us to break down the problem of understanding a visual scene into a rapid series of computationally less demanding, localized visual analysis problems. 
"Visually salient" are those location in the visual wolrd that automatically attract attention.

\subsection{Classification}
[Quang]
% which classifiers
% how they work
% how they operate in the system
\subsection{Visualization}
[Nick]
% 3 views
