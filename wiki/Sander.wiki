#summary Sander's research log
== 06/09/2010==
  * Looking into saliency maps.
    A straight forward way to compute the simalirity between two images would be to just substract two saliency maps.

  * Worked a bit more on the image download script.
    
    Usage: python scrapper_gallery deviant1 deviant2 deviant3 ..
    
    Accepts a list of deviants. For each deviant it will download the full images and thumbtails to the folder images/deviant/

== 06/08/2010==
  * In case we store everything in a database we could maybe use a database scheme like this?
  http://ppis-deviantart.googlecode.com/files/db.PNG

  Filename refers to image filename. Can be the full image or one of the thumbs.

  * We might want to consider to only download the thumbs. The thumbs of 300 width might be sufficient for most features, while the thumbs are much smaller than the full images.

== 06/07/2010==
  * Working on extracting all images from a gallery of a deviant.
    Looked at the matlab code of Albert. Seems he does not extract all images for each deviant. The first backend page only shows like the first 2.5 pages of the gallery. You need to modify the offset to show the remaining image information.

  * I'm rewriting the code in python. Using the SGMLParser class to find the backend url in the gallery page. Using xml.sax to parse the backend page.
    
  * The backend page contains the following information:
    * Image link
    * Thumbtail links (two versions: 300 width and 150 height)
    * Title
    * Category information
    * Keywords
    * Etc. 

  * Downloads about 60 images per minute.

== 06/03/2010==
  * Worked together with Bart on extracting all friends from a deviant. With this information we can generate a graph of all connected deviants. 
  The friends selection is limited to special members (premium members).

== 06/02/2010==
==== A Model of Saliency-Based Visual Attention for Rapid Scene Analysis" and "COMPUTATIONAL MODELLING OFVISUAL ATTENTION ====
  * Read the papers "A Model of Saliency-Based Visual Attention for Rapid Scene Analysis" and  "COMPUTATIONAL MODELLING OFVISUAL ATTENTION"
  * Assumes primates decompose visual input into a set of topographic feature maps. Spatial locations compete for saliency in each map. A saliency map is constructed from this and the attention point is derived from this.
  
  * Maps are constructed from different visual features like color, intensity and orientation. Then in various steps the saliency map is constructed. The point with the biggest output is the attention point.

  * _Discussion point:_ Papers seem to be focussed on finding saliency. The features could certainly be used to find similar images, but what if two images have the same attention points but are actually pretty different?  

== 05/02/2010==
Made a research log.